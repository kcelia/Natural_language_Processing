{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zOohodXxCrJ",
    "outputId": "6a673d58-a30d-4298-b321-556f1a49fd06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv \n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from google.colab import files\n",
    "\n",
    "!pip install bert-for-tf2\n",
    "!pip install sentencepiece \n",
    "\n",
    "import bert\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.datasets import imdb\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Embedding, Flatten, GlobalMaxPool1D, Dense, Dropout\n",
    "from keras.layers.convolutional import MaxPooling1D, Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-9Y1WwPE90_"
   },
   "source": [
    " # Challenge\n",
    " \n",
    "The Challenge will be to identify the sentiment in the text in the imdb_reviews. The data imdb_reviews for the training has to be taken from tensorflow tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gUDNywcw8yFy"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPiN1Yl8zrD9"
   },
   "source": [
    "# Load traindata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-6SEJ78MzUiZ"
   },
   "outputs": [],
   "source": [
    "vocab_size = None # We take all the words \n",
    "index_from = 3\n",
    "\n",
    "(X_train, y_train), (X_valid, y_valid) = imdb.load_data(num_words=vocab_size,\n",
    "                                                      index_from=index_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y18VupdK7rOP"
   },
   "source": [
    "## Exploring traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFBPeNYjF7Rm",
    "outputId": "55433526-e359-4293-a3c3-d0deb8908aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,), (25000,), (25000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB contains 25,000 movie reviews\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cW9Cvx-zF8Tx",
    "outputId": "45c7f33a-e14c-4d5e-e744-4d675f7715c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 141, 133)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # The sequences have different sizes\n",
    " len(X_train[0]),  len(X_train[2]), len(X_valid[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHnbQ5uoF8eS",
    "outputId": "1ac00678-8a8a-493f-82b3-17ba6a074afb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # The review has been encoded as a sequence of integers\n",
    " X_train[0][:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFjUpqoAECHL",
    "outputId": "6df06b38-1218-427d-a656-9f1c98e9dfaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes 0: negative review, 1: positive review.\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "VHaLRJHq8AWM",
    "outputId": "1d08eb66-e26f-4fdf-b46a-4e63ff00efba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>vectors</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12769</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 6, 801, 11138, 2284, 10119, 11513, 267, 40, 6, 1665, 200, 17590, 15224, 11, 28238, 5, 430, 742, 214, 60, 19, 84, 59, 764, 28, 11135, 41, 19, 4, 339, 7, 35, 154, 2368, 2915, 15, 59, 659, 11, 4, 162, 313, 59, 5, 41, 1633, 189, 19102, 4115, 328, 4, 64, 2602, 52, 155, 44, 14, 4995, 818, 4, 33835, 184, 5006, 78, 262, 54, 10119, 22053, 19, 4, 3558, 2915, 5, 50, 26, 57, 2629, 42, 836, 8, 30, 69, 14, 22, 5346, 10031, 1346, 18, 342, 2289, 257, 1076, 53, 2526, 74, 4, 236, 84, 267, ...]</td>\n",
       "      <td>&lt;START&gt; a typical goth chick rainbow harvest looking like a cross between winona ryder in beetlejuice and boy george gets even with people she feels have wronged her with the help of an old haunted mirror that she finds in the new house she and her mom horror mainstay karen black the only remotely good thing about this travesty buy the acting's pretty laughably bad especially when rainbow interacts with the aforementioned mirror and there are no scares or suspense to be had this film inexplicably spawned thus for 3 sequels each slightly more atrocious than the last people looking for a similarly themed but far superior cinematic endeavor would be well advised to just search out the episode of friday the 13th the series where a geeky girl finds an old cursed compact mirror that packs more chills in it's scant 40 minutes than this whole franchise has provided across it's 4 films br br my grade d br br eye candy charlie spradling provides the obligatory t a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   reviews\n",
       "12769       0  ...  <START> a typical goth chick rainbow harvest looking like a cross between winona ryder in beetlejuice and boy george gets even with people she feels have wronged her with the help of an old haunted mirror that she finds in the new house she and her mom horror mainstay karen black the only remotely good thing about this travesty buy the acting's pretty laughably bad especially when rainbow interacts with the aforementioned mirror and there are no scares or suspense to be had this film inexplicably spawned thus for 3 sequels each slightly more atrocious than the last people looking for a similarly themed but far superior cinematic endeavor would be well advised to just search out the episode of friday the 13th the series where a geeky girl finds an old cursed compact mirror that packs more chills in it's scant 40 minutes than this whole franchise has provided across it's 4 films br br my grade d br br eye candy charlie spradling provides the obligatory t a\n",
       "\n",
       "[1 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore original text from Keras’s imdb dataset\n",
    "\n",
    "# imdb.get_word_index: dictionary that provides the word of the corresponding integer\n",
    "# word_to_index      : dictionary that links each word to a unique integer\n",
    "\n",
    "word_to_index = {k: (v + index_from) for k, v in imdb.get_word_index().items()}\n",
    "word_to_index[\"<PAD>\"]    = 0 # O is usually the padding character.\n",
    "word_to_index[\"<START>\"]  = 1 # Start of the sequence \n",
    "word_to_index[\"<UNK>\"]    = 2 # Unknown word\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# Reversing the dictionary. \n",
    "index_to_word = dict(map(reversed, word_to_index.items()))\n",
    "\n",
    "df_train = pd.DataFrame(data=list(zip(y_train, X_train)), columns=[\"labels\", \"vectors\"])\n",
    "\n",
    "df_train['reviews'] = df_train.vectors.apply(lambda sent: ' '.join([index_to_word[indx] \\\n",
    "                                                                 for indx in sent if indx in index_to_word.keys()]))\n",
    "\n",
    "# Shuffle the data\n",
    "df_train = df_train.sample(frac=1)\n",
    "\n",
    "df_train.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZqslRVYJUJaB",
    "outputId": "10b967b2-5f05-4313-e441-732db385c8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 88585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88685, 88584)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of unique words in our corpus\n",
    "list_unique_words = list(df_train.reviews.str.split(' ', expand=True).stack().unique())\n",
    "print(f\"Vocabulary: {len(list_unique_words)}\")\n",
    "\n",
    "vocab_size = len(list_unique_words) + 100 if vocab_size is None else vocab_size\n",
    "\n",
    "vocab_size, len(imdb.get_word_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdVVb10AEvAV",
    "outputId": "6f28a50e-7ea6-47d2-81b2-fef8cac39248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\x91', '…', '\\x96', '\\x97', '–', '§', '¨', '®', '‘', '\\xa0', '\\xad', '>', '´', '\\uf0b7', '¦', '«', '¤', '°', '\\x9e', '\\x8e', '\\x8d', ' ', '·', '\\x08', '’', '“', '\\x80', \"'\", '¡', '\\x84', '»', '\\x85', '£', '₤', '\\x10', '¢', '¿', '\\x9a', '<', '”', '\\x95'}\n",
      "{'99', '1000000', '666', '153', '1813', '1201', '00817', '142', '1929', '62', '1958', '1940', '350', '1861', '1415', '52', '087', '6000', '1000', '139', '73', '502', '5250', '24', '26', '21849907', '280', '998', '1937', '1894', '203', '428', '262', '230', '94', '5', '53', '1832', '78', '02', '225', '25', '2019', '223', '32', '1900', '1994', '61', '409', '1939', '31', '1146', '974', '1971', '2050', '1986', '1820', '1927', '1945', '171', '330', '1948', '75', '442', '2009', '1987', '5000', '3', '34', '214', '75054', '64', '735', '1992', '231', '2', '21849889', '4000', '123', '2010', '65', '1408', '8230', '1547', '420', '103', '571', '00015', '197', '63', '1809', '19', '83', '5400', '56', '1897', '1889', '15', '020410', '1', '1989', '7600', '116', '0283181', '1991', '1893', '0073891', '1907', '66', '9999', '261', '1975', '7', '183', '1957', '618', '1888', '2080', '6', '1936', '1202', '20000', '127', '04', '0408790', '74', '1979', '1886', '1473', '500000', '45', '194', '18137', '1138', '109', '1200', '819', '105', '16', '1968', '222', '700', '95', '1956', '1492', '147', '1921', '1627', '192', '465', '454', '2600', '1905', '9484', '911', '138', '1985', '1964', '101', '2060', '11001001', '1692', '999', '469', '003830', '2005', '987', '249', '1040', '5539', '2000', '905', '1859', '177', '241', '451', '285', '82', '1895', '152', '28', '1838', '05', '79', '170', '395', '2002', '55', '112', '22', '3500', '1904', '660', '1700', '320', '215', '6342', '106', '0077713', '1876', '155', '978', '87', '1865', '1701', '1873', '1780', '1981', '9', '737', '1454', '36', '608', '30', '1880', '747', '117', '1914', '1300', '1863', '227', '2033', '1852', '578', '128', '210', '111', '46', '1966', '72', '00', '48', '2090', '242', '21849890', '937', '607', '370', '160', '2044', '81', '1890', '425', '1980', '60', '427', '305', '555', '84', '90210', '820', '2020', '372', '8', '91', '1892', '1870', '131', '8217', '23', '817', '165', '17', '1594', '8000', '1840', '206', '1911', '1965', '2222', '1967', '1610', '06', '236', '1001', '1928', '1982', '357', '1963', '5200', '19796', '0093638', '2003', '1050', '216', '221', '006', '1931', '400', '1930', '2030', '1906', '1977', '0059080', '10000000000000', '175', '47', '1998', '41', '273', '041', '1836', '1984', '149', '57', '089', '1318', '2007', '900', '3462', '917', '1902', '430', '1996', '1961', '1875', '67', '378', '09', '1814', '0449040', '1917', '20', '007', '1918', '90', '50', '200', '14', '1962', '33', '1933', '1915', '0281661', '2480', '190', '1830', '0363163', '440', '2100', '1942', '16787', '62229249', '1973', '2015', '98', '1561', '1500', '1864', '68', '2038', '7739', '2500', '130', '1800', '701', '970', '0', '1949', '1337580', '102', '475', '2046', '169', '1944', '115', '132', '405', '1909', '365', '158', '1990', '9000', '1923', '1959', '29', '707', '1947', '7212', '270', '146', '850', '401', '1993', '1100', '1855', '360', '2036', '498', '35', '2004', '2047', '788', '1970', '185', '92', '140', '356', '0083', '43', '114', '1926', '576', '1974', '110', '145', '232', '163', '21', '18', '1887', '1941', '1824', '21699', '1952', '0000000000001', '1997', '269', '137', '166', '1983', '2001', '275', '250000', '2040', '600', '1938', '598947', '0079', '1816', '96', '93', '1912', '76', '2642', '248', '1847', '1614', '1871', '0962736', '3200', '58', '1969', '2017', '71', '1862', '1935', '54', '480', '1999', '1896', '22101', '2257', '1215', '1860', '168', '201', '11', '1960', '637', '164', '740', '20001', '08', '136', '2772', '3000', '4500', '134', '1910', '3516', '188', '260', '8763', '8700', '161', '2013', '6200', '70', '0077247', '97', '250', '2054', '1837', '3199', '1920', '1972', '39', '1988', '2008', '1922', '0250274', '42', '849', '193', '1976', '209', '274', '1794', '1925', '89', '01', '156', '1874', '800', '44', '303', '234', '37', '540', '1850', '07', '1954', '157', '2012', '151', '85', '10', '1978', '1903', '233', '1919', '104', '108', '2031', '336', '1932', '1901', '1839', '4', '1844', '2200', '69', '7890', '332960073452', '1946', '300', '2006', '002', '38', '2151', '050', '220', '1955', '1846', '1812', '6723', '2023', '49', '1913', '1775', '180', '529', '59', '278', '3012', '1660', '1899', '120', '1951', '1950', '1908', '1798', '100', '2053', '1898', '500', '1953', '345', '240', '750', '1924', '029', '914', '950', '195', '13', '001', '921', '80', '88', '125', '713', '237', '272', '1943', '2210', '1916', '03', '51', '86', '2022', '1854', '204', '450', '1801', '1995', '1805', '7300', '27', '2400', '2070', '12', '135', '000', '00001', '2035', '878', '12383499143743701', '77', '1790', '1853', '40', '150', '477', '107', '1881', '1600', '0080', '1934'}\n"
     ]
    }
   ],
   "source": [
    "# Non-alphanumeric characters & digits\n",
    "\n",
    "non_alphanumetique, degits = set(), set()\n",
    "\n",
    "for review in df_train.reviews:\n",
    "    non_alphanumetique |= set(re.findall(r'\\W', review))   \n",
    "    degits |= set(re.findall(r'\\d+', review))   \n",
    "\n",
    "print(non_alphanumetique)\n",
    "print(degits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agkc8IJhIa1U"
   },
   "source": [
    "## Create the dataset for the trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D-aTxGFmzxuC"
   },
   "outputs": [],
   "source": [
    "# pad dataset to a maximum review length in words\n",
    "# we will fill the unused word slots with zeros\n",
    "max_words = 600\n",
    "X_train = sequence.pad_sequences(df_train.vectors, value=word_to_index[\"<PAD>\"], maxlen=max_words)\n",
    "X_valid = sequence.pad_sequences(X_valid, value=word_to_index[\"<PAD>\"], maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rde-F_7f7FJi"
   },
   "source": [
    "## Load testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "V0qQmQ5-CXcM"
   },
   "outputs": [],
   "source": [
    "def preprocessing(df, usecols=[], nb=5, verbose=True):\n",
    "\n",
    "    if verbose: \n",
    "        print(f\"{df.columns}\")\n",
    "        print(f\"DF before:\\n{df.head(nb)}\\n\")\n",
    "    \n",
    "    non_charac, digits = set(), set()\n",
    "    for x in df[usecols[0]]:\n",
    "        non_charac |= set(re.findall(r'\\W', x))   \n",
    "        digits     |= set(re.findall(r'\\d+', x))       \n",
    "\n",
    "    # Remove the Non-alphanumeric\n",
    "    if verbose: \n",
    "        print(f\"Remove all these non-alphanumeric characters :\\n{non_charac}\")\n",
    "    df['preprocessed_text'] = df[usecols[0]].apply(lambda x: re.sub(r'\\W', ' ', x))\n",
    "    \n",
    "    # Lower case\n",
    "    df['preprocessed_text'] = df['preprocessed_text'].apply(lambda x: x.lower())\n",
    "\n",
    "    # Start\n",
    "    df['preprocessed_text'] = df['preprocessed_text'].apply(lambda x: re.sub(r'^b ', '<START> ', x))\n",
    "       \n",
    "    # Remove the extra spaces at the middle, the beginning and the end of the text    \n",
    "    df['preprocessed_text'] = df['preprocessed_text'].apply(lambda x: re.sub(r'\\s+', ' ', x))        \n",
    "    df['preprocessed_text'] = df['preprocessed_text'].apply(lambda x: re.sub(r'(^\\s+|\\s+$)', ' ', x)) \n",
    "\n",
    "    df['vectors'] = df['preprocessed_text'].apply(lambda sentence: [word_to_index[word] for word in sentence.split() \\\n",
    "                                                                    if word in word_to_index.keys()] ) \n",
    "    \n",
    "    if verbose: \n",
    "        print(f\"\\n{df.columns}\")\n",
    "        print(f\"DF after:\\n{df.head(nb)}\\n\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gb3YXIY77EST",
    "outputId": "dcb3198a-97dd-4e31-fc88-bcd6bcb9dc44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'sentences'], dtype='object')\n",
      "DF before:\n",
      "   Id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         sentences\n",
      "0   1  b\"A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel's previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.<br /><br />The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual's struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin's whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film's last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.<br /><br />This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel's most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view 'Nazarin' is second only to 'The Exterminating Angel', in terms of his Mexican movies, and is certainly near the top of the list of Bunuel's total filmic output.\"\n",
      "\n",
      "Remove all these non-alphanumeric characters :\n",
      "{'{', '^', '/', '(', '}', ';', '#', '=', '\\\\', '-', '+', ':', '$', '~', '?', '>', '|', '@', '[', ']', ' ', '.', '%', '\"', \"'\", '!', '<', '&', '*', ')', '`', ','}\n",
      "\n",
      "Index(['Id', 'sentences', 'preprocessed_text', 'vectors'], dtype='object')\n",
      "DF after:\n",
      "   Id  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          vectors\n",
      "0   1  ...  [1, 6, 34929, 700, 787, 7, 6, 180, 22005, 2325, 8766, 4, 8238, 15, 6045, 14111, 16, 502, 8, 2715, 11, 112, 502, 8, 376, 6, 1685, 22568, 9108, 19, 6, 4900, 7, 8602, 17, 35, 10564, 39, 27, 2662, 999, 7, 22, 231, 12, 16, 35, 17206, 676, 8, 6491, 19, 117, 278, 5, 576, 2706, 25786, 190, 9471, 111, 7, 14111, 590, 960, 2662, 108, 11, 1303, 7, 4, 116, 3698, 9, 321, 1321, 5, 756, 10, 10, 4, 756, 5693, 9, 142, 15, 16, 4087, 174, 11, 93, 289, 153, 303, 11, 5001, 12, 3277, 4, 2267, ...]\n",
      "\n",
      "[1 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_raw = pd.read_csv(\"/content/testSentimentDataforValidation.csv\")\n",
    "\n",
    "df_test = preprocessing(df_test_raw.copy(), usecols=['sentences'], nb=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "H-3NUrAIAMvF"
   },
   "outputs": [],
   "source": [
    "# pad dataset to a maximum review length in words\n",
    "# we will fill the unused word slots with zeros\n",
    "max_words = 600\n",
    "X_test = sequence.pad_sequences(df_test.vectors, value=word_to_index[\"<PAD>\"], maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltv8uVb6z4NF"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRA7tqZRzxxR",
    "outputId": "904cb1c5-0806-4fbf-e860-86ee531c33a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 600, 32)           2837920   \n",
      "_________________________________________________________________\n",
      "module_wrapper (ModuleWrappe (None, 600, 64)           4160      \n",
      "_________________________________________________________________\n",
      "module_wrapper_1 (ModuleWrap (None, 600, 32)           6176      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               8250      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,856,757\n",
      "Trainable params: 2,856,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 32, input_length=max_words))\n",
    "model.add(Conv1D(64, 2, padding='same', activation='relu'))\n",
    "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4RkbTjb2z5-"
   },
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ASOcnvf2x_c",
    "outputId": "9ac7f3b7-ff4e-47f7-b0de-19b752903660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 53s 265ms/step - loss: 0.5309 - accuracy: 0.7106 - val_loss: 0.3631 - val_accuracy: 0.8391\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 51s 263ms/step - loss: 0.2564 - accuracy: 0.8959 - val_loss: 0.2842 - val_accuracy: 0.8815\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 53s 270ms/step - loss: 0.1247 - accuracy: 0.9571 - val_loss: 0.3016 - val_accuracy: 0.8808\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 50s 257ms/step - loss: 0.0448 - accuracy: 0.9873 - val_loss: 0.3791 - val_accuracy: 0.8726\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 53s 270ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.4173 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 52s 267ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.4574 - val_accuracy: 0.8762\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 52s 263ms/step - loss: 9.5207e-04 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8751\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 53s 273ms/step - loss: 4.4942e-04 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.8763\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 52s 264ms/step - loss: 2.5879e-04 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.8756\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 53s 271ms/step - loss: 1.6485e-04 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.8759\n",
      "Accuracy: 87.59%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "model.fit(X_train, df_train.labels, validation_data=(X_valid, y_valid), epochs=10, batch_size=128, verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqNOz09EBe-e"
   },
   "source": [
    "# Testing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_G5-R2bszUtS"
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "predictions = model.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ci6av9t6JkD9",
    "outputId": "720000db-f1ea-45d6-f033-56ae56e8c2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb negative reviews: 5368\n",
      "Nb positif reviews:4360\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nb negative reviews: {(np.floor(predictions * 2) == 0).sum()}\")\n",
    "print(f\"Nb positif reviews:{(np.floor(predictions * 2) == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UkwPYZdjJkG6"
   },
   "outputs": [],
   "source": [
    "df_test[\"predictions\"] = np.floor(predictions * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Yyq4wgkBpjL",
    "outputId": "96ab1cd9-89df-4312-a443-67737e937423"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5127, 2416)"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.floor(predictions * 2) == 0).sum(), (np.floor(predictions * 2) == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "id": "X1T0yp_LUUJQ",
    "outputId": "5955987c-912e-425b-c8aa-8d28174f99df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>vectors</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b\"A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel's previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.&lt;br /&gt;&lt;br /&gt;The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual's struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin's whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film's last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.&lt;br /&gt;&lt;br /&gt;This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel's most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view 'Nazarin' is second only to 'The Exterminating Angel', in terms of his Mexican movies, and is certainly near the top of the list of Bunuel's total filmic output.\"</td>\n",
       "      <td>&lt;START&gt; a blackly comic tale of a down trodden priest nazarin showcases the economy that luis bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss as an output from his mexican era of film making it was an invaluable talent to possess with little money and extremely tight schedules nazarin however surpasses many of bunuel s previous mexican films in terms of the acting francisco rabal is excellent narrative and theme br br the theme interestingly is something that was explored again in viridiana made three years later in spain it concerns the individual s struggle for humanity and altruism amongst a society that rejects any notion of virtue father nazarin however is portrayed more sympathetically than sister viridiana whereas the latter seems to choose charity because she wishes to atone for her perceived sins nazarin s whole existence and reason for being seems to be to help others whether they or we like it or not the film s last scenes in which he casts doubt on his behaviour and in a split second has to choose between the life he has been leading or the conventional life that is expected of a priest are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not br br this is a remarkable film and i would urge anyone interested in classic cinema to seek it out it is one of bunuel s most moving films and encapsulates many of his obsessions frustrated desire mad love religious hypocrisy etc in my view nazarin is second only to the exterminating angel in terms of his mexican movies and is certainly near the top of the list of bunuel s total filmic output</td>\n",
       "      <td>[1, 6, 34929, 700, 787, 7, 6, 180, 22005, 2325, 8766, 4, 8238, 15, 6045, 14111, 16, 502, 8, 2715, 11, 112, 502, 8, 376, 6, 1685, 22568, 9108, 19, 6, 4900, 7, 8602, 17, 35, 10564, 39, 27, 2662, 999, 7, 22, 231, 12, 16, 35, 17206, 676, 8, 6491, 19, 117, 278, 5, 576, 2706, 25786, 190, 9471, 111, 7, 14111, 590, 960, 2662, 108, 11, 1303, 7, 4, 116, 3698, 9, 321, 1321, 5, 756, 10, 10, 4, 756, 5693, 9, 142, 15, 16, 4087, 174, 11, 93, 289, 153, 303, 11, 5001, 12, 3277, 4, 2267, ...]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ... predictions\n",
       "0   1  ...         1.0\n",
       "\n",
       "[1 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaUL92MqOfrc"
   },
   "source": [
    "## Save the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "31gzcxg1Oj1N",
    "outputId": "aebd813e-5bee-4232-82b8-7919251d4372"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_10b64983-7484-4e5b-b1ab-475ae32d3795\", \"results.csv\", 137785)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[['Id', 'predictions']].to_csv('results.csv') \n",
    "\n",
    "files.download('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TWiuIrWTVyq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hackathon - Challenge 2 - sentiment classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
